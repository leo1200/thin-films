{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38975892",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Soft-DTW(y1, y2) = 25.935562133789062\n",
      "Soft-DTW(y1, y3) = 41.95087432861328\n",
      "Soft-DTW(y1, y4) = 3.7997639179229736\n",
      "Soft-DTW(y1, y5) = 0.37580013275146484\n",
      "L2(y1, y2) = 12.967781066894531\n",
      "L2(y1, y3) = 20.97543716430664\n",
      "L2(y1, y4) = 1.8998819589614868\n",
      "L2(y1, y5) = 0.18790006637573242\n"
     ]
    }
   ],
   "source": [
    "import jax.numpy as jnp\n",
    "from typing import Tuple\n",
    "import jax\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "def _softmin(v: jnp.ndarray, gamma: float, axis: int = -1) -> jnp.ndarray:\n",
    "  \"\"\"JAX implementation of soft-min operator using logsumexp for stability.\"\"\"\n",
    "  return -gamma * jax.nn.logsumexp(-v / gamma, axis=axis)\n",
    "\n",
    "def _soft_dtw(t1: jnp.ndarray, t2: jnp.ndarray, gamma) -> float:\n",
    "\n",
    "  def body(\n",
    "      carry: Tuple[jnp.ndarray, jnp.ndarray],\n",
    "      current_antidiagonal: jnp.ndarray\n",
    "  ) -> Tuple[Tuple[jnp.ndarray, jnp.ndarray], jnp.ndarray]:\n",
    "    # modified from: https://github.com/khdlr/softdtw_jax\n",
    "    two_ago, one_ago = carry\n",
    "\n",
    "    diagonal, right, down = two_ago[:-1], one_ago[:-1], one_ago[1:]\n",
    "    best = _softmin(\n",
    "        jnp.stack([diagonal, right, down], axis=-1), gamma, axis=-1\n",
    "    )\n",
    "\n",
    "    next_row = best + current_antidiagonal\n",
    "    next_row = jnp.pad(next_row, (1, 0), constant_values=jnp.inf)\n",
    "\n",
    "    return (one_ago, next_row), next_row\n",
    "\n",
    "  # calculate euclidian pairwise distance matrix\n",
    "  dist = (t1[:, None] - t2[None, :]) ** 2\n",
    "\n",
    "  n, m = dist.shape\n",
    "  if n < m:\n",
    "    dist = dist.T\n",
    "    n, m = m, n\n",
    "\n",
    "  model_matrix = jnp.full((n + m - 1, n), fill_value=jnp.inf)\n",
    "  mask = np.tri(n + m - 1, n, k=0, dtype=bool)\n",
    "  mask = mask & mask[::-1, ::-1]\n",
    "  model_matrix = model_matrix.T.at[mask.T].set(dist.ravel()).T\n",
    "\n",
    "  init = (\n",
    "      jnp.pad(model_matrix[0], (1, 0), constant_values=jnp.inf),\n",
    "      jnp.pad(\n",
    "          model_matrix[1] + model_matrix[0, 0], (1, 0),\n",
    "          constant_values=jnp.inf\n",
    "      )\n",
    "  )\n",
    "\n",
    "  (_, carry), _ = jax.lax.scan(body, init, model_matrix[2:])\n",
    "  return carry[-1]\n",
    "\n",
    "def _debiased_soft_dtw(t1: jnp.ndarray, t2: jnp.ndarray, gamma: float) -> float:\n",
    "    dtw12 = _soft_dtw(t1, t2, gamma)\n",
    "    dtw11 = _soft_dtw(t1, t1, gamma)\n",
    "    dtw22 = _soft_dtw(t2, t2, gamma)\n",
    "    return dtw12 - 0.5 * (dtw11 + dtw22)\n",
    "\n",
    "def get_chirped_signal(time, phase_velocity, phase_acceleration):\n",
    "  return jnp.sin(time * phase_velocity + 0.5 * phase_acceleration * time ** 2)\n",
    "\n",
    "# --- New functions ---\n",
    "def l2_loss(t1: jnp.ndarray, t2: jnp.ndarray) -> float:\n",
    "  \"\"\"Calculates the Mean Squared Error (L2 loss).\"\"\"\n",
    "  return jnp.mean((t1 - t2)**2)\n",
    "\n",
    "# --- Parameters ---\n",
    "time = jnp.linspace(0.0, 6.0, 100) # Reduced points for faster computation\n",
    "true_velocity = 4.0\n",
    "true_acceleration = -0.1\n",
    "true_signal = get_chirped_signal(time, true_velocity, true_acceleration)\n",
    "\n",
    "# Parameter range for comparison\n",
    "velocities = jnp.linspace(3.0, 5.0, 50) # Grid resolution\n",
    "accelerations = jnp.linspace(-0.2, 0.2, 50) # Grid resolution\n",
    "V, A = jnp.meshgrid(velocities, accelerations)\n",
    "\n",
    "# Soft-DTW parameter\n",
    "gamma = 0.5\n",
    "\n",
    "# --- Loss Calculation (Vectorized) ---\n",
    "\n",
    "# Function to compute losses for a single (v, a) pair\n",
    "@jax.jit\n",
    "def compute_losses_for_params(v, a):\n",
    "    test_signal = get_chirped_signal(time, v, a)\n",
    "    sdtw_loss = _debiased_soft_dtw(true_signal, test_signal, gamma)\n",
    "    mse_loss = l2_loss(true_signal, test_signal)\n",
    "    return sdtw_loss, mse_loss\n",
    "\n",
    "# Vectorize the function to work over the grid\n",
    "# We map over the first axis of V and A (which are 2D arrays from meshgrid)\n",
    "# This effectively calculates losses for each (v, a) pair in the grid\n",
    "vectorized_compute_losses = jax.vmap(jax.vmap(compute_losses_for_params, in_axes=(0, 0)), in_axes=(0, 0))\n",
    "\n",
    "# Calculate losses over the entire grid\n",
    "# Convert meshgrid results to JAX arrays before passing\n",
    "sdtw_losses_grid, l2_losses_grid = vectorized_compute_losses(jnp.array(V), jnp.array(A))\n",
    "\n",
    "# --- Visualization ---\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 6))\n",
    "\n",
    "# Plot L2 Loss\n",
    "cf1 = axes[0].contourf(V, A, l2_losses_grid, levels=50, cmap='viridis')\n",
    "fig.colorbar(cf1, ax=axes[0], label='Loss Value')\n",
    "axes[0].contour(V, A, l2_losses_grid, levels=10, colors='white', alpha=0.5, linewidths=0.5)\n",
    "axes[0].plot(true_velocity, true_acceleration, 'ro', markersize=8, label='True Parameters')\n",
    "axes[0].set_title(f'L2 (MSE) Loss Landscape')\n",
    "axes[0].set_xlabel('Phase Velocity')\n",
    "axes[0].set_ylabel('Phase Acceleration')\n",
    "axes[0].legend()\n",
    "axes[0].grid(True, linestyle='--', alpha=0.6)\n",
    "\n",
    "\n",
    "# Plot Soft-DTW Loss\n",
    "# Use a potentially different level scaling for better visualization if needed\n",
    "# Clipping max value can help if outliers dominate color scale\n",
    "max_sdtw_plot = jnp.percentile(sdtw_losses_grid, 99) # Clip to 99th percentile for better contrast\n",
    "cf2 = axes[1].contourf(V, A, jnp.clip(sdtw_losses_grid, a_max=max_sdtw_plot), levels=50, cmap='viridis')\n",
    "fig.colorbar(cf2, ax=axes[1], label='Loss Value')\n",
    "axes[1].contour(V, A, jnp.clip(sdtw_losses_grid, a_max=max_sdtw_plot), levels=10, colors='white', alpha=0.5, linewidths=0.5)\n",
    "axes[1].plot(true_velocity, true_acceleration, 'ro', markersize=8, label='True Parameters')\n",
    "axes[1].set_title(f'Debiased Soft-DTW Loss Landscape (gamma={gamma})')\n",
    "axes[1].set_xlabel('Phase Velocity')\n",
    "axes[1].set_ylabel('Phase Acceleration')\n",
    "axes[1].legend()\n",
    "axes[1].grid(True, linestyle='--', alpha=0.6)\n",
    "\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# --- Comparison Summary ---\n",
    "\n",
    "print(\"\\nComparison Summary:\")\n",
    "print(\"-\" * 20)\n",
    "print(f\"True Parameters: Velocity={true_velocity}, Acceleration={true_acceleration}\")\n",
    "min_l2_idx = jnp.unravel_index(jnp.argmin(l2_losses_grid), l2_losses_grid.shape)\n",
    "min_sdtw_idx = jnp.unravel_index(jnp.argmin(sdtw_losses_grid), sdtw_losses_grid.shape)\n",
    "\n",
    "print(f\"L2 Loss Minimum Found at: Velocity={V[min_l2_idx]:.3f}, Acceleration={A[min_l2_idx]:.3f} (Value: {l2_losses_grid[min_l2_idx]:.4f})\")\n",
    "print(f\"Soft-DTW Loss Minimum Found at: Velocity={V[min_sdtw_idx]:.3f}, Acceleration={A[min_sdtw_idx]:.3f} (Value: {sdtw_losses_grid[min_sdtw_idx]:.4f})\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "f1uids",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
